{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ff773-ea3c-44f1-af96-5f2088831324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import json as js\n",
    "import glob\n",
    "import re\n",
    "import base64\n",
    "from itertools import product\n",
    "from itertools import cycle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aade1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomError(RuntimeError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c5586-f485-48e0-961f-3a7f8523de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = Path(\"logs/async_requests.log\")\n",
    "log_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, mode=\"a\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 3 #DELAY BY SECONDS\n",
    "\n",
    "RETRY_FILE = \"retry_gpt_global.txt\"\n",
    "\n",
    "SEMAPHORE = asyncio.Semaphore(300) # Decrease if toooo big\n",
    "\n",
    "endpoints = \"YOUR ENDPOINT\"\n",
    "api_keys = \"YOUR API KEY\"\n",
    "\n",
    "endpoint_cycle = cycle(endpoints)\n",
    "api_key_cycle = cycle(api_keys)\n",
    "\n",
    "def get_next_endpoint_and_key():\n",
    "    return next(endpoint_cycle), next(api_key_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa00447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ids(directory):\n",
    "    integers = set()\n",
    "    pattern = re.compile(r'^(\\d+)_')\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            integers.add(int(match.group(1)))\n",
    "    \n",
    "    return sorted(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056fa75-c08a-4f57-b1a1-3acf526d6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_graph_data_by_pk(p_alias:str, size:str, index:int, fmt=\"edge_list\") -> str:\n",
    "    \"\"\"Find the path of graph data file for (FMT, P_ALIAS, SIZE, INDEX)\"\"\"\n",
    "    if size not in [\"exlarge\", \"small\"]:\n",
    "        raise CustomError(f\"Invalid size {size}.\")\n",
    "\n",
    "    term = \"general\" if p_alias == \"SBM\" else \"special\"\n",
    "\n",
    "    str_pattern = f\"{index}_{p_alias}_*.txt\"\n",
    "    files = glob.glob(f\"data/{size}_{term}_graphs/{fmt}/{p_alias}/{str_pattern}\")\n",
    "\n",
    "    for file in files:\n",
    "        match = re.match(rf\"data/{size}_{term}_graphs/{fmt}/{p_alias}/(\\d+)_.*\\.txt$\", file)\n",
    "        if match and int(match.group(1)) == index:\n",
    "            return file\n",
    "\n",
    "    raise CustomError(f\"Filename not found for {fmt} {p_alias} {size} {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522174c-1f97-4147-8e77-5d82f60792d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph_from_edge_list(filename:str):\n",
    "    edges = []\n",
    "    nodes = set()\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            node1, node2 = map(int, line.split())\n",
    "            \n",
    "            edges.append((node1, node2))\n",
    "            \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "    \n",
    "    return sorted(list(nodes)), sorted(list(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dca9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_alias(pattern: str) -> str:\n",
    "    if pattern not in [\"Cycle\",\"Star\", \"Path\", \"Grid\", \"clustered graph\"]:\n",
    "        raise CustomError(f\"Invalid pattern {pattern}\")\n",
    "    if pattern == \"clustered graph\":\n",
    "        p_alias = \"SBM\"\n",
    "    else:\n",
    "        p_alias = pattern\n",
    "    return p_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ac64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def prepare_data(p_alias:str, size:str, i:int):\n",
    "    term = \"general\" if p_alias == \"SBM\" else \"special\"\n",
    "\n",
    "    i_path1 = f\"images/{size}_{term}_graphs/edge_list/{p_alias}/{i}_{p_alias}_iter10.png\"\n",
    "    i_path2 = f\"images/{size}_{term}_graphs/edge_list/{p_alias}/{i}_{p_alias}_iter50.png\"\n",
    "    images = [encode_image(i_path1), encode_image(i_path2)]\n",
    "    \n",
    "    p_path1 = f\"layouts/{size}_{term}_graphs/edge_list/{p_alias}/{i}_{p_alias}_iter10.json\"\n",
    "    p_path2 = f\"layouts/{size}_{term}_graphs/edge_list/{p_alias}/{i}_{p_alias}_iter50.json\"\n",
    "    with open(p_path1, \"r\") as f:\n",
    "        p1 = js.load(f)\n",
    "    with open(p_path2, \"r\") as f:\n",
    "        p2 = js.load(f)\n",
    "    pos = [p1, p2]\n",
    "\n",
    "    return images, pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c2d3d-5cb9-461e-9458-a43e27faf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_graph_to_str_el(f):\n",
    "    n, e = read_graph_from_edge_list(f)\n",
    "    return n, str(e)\n",
    "\n",
    "async def perform_test(session, test_pks:list, p_alias:str, ids:list, debug=False, virtual=True, console=True):\n",
    "    tasks = []\n",
    "    valid_requirements = [\"edge\", \"distance\", \"community\"] if p_alias == \"SBM\" else [\"edge\", \"distance\"]\n",
    "    \n",
    "    debug_count = 0\n",
    "    model, size, modality, task = test_pks\n",
    "\n",
    "    if task not in valid_requirements:\n",
    "        raise CustomError(f\"Invalid requirement {task} for {p_alias}.\")\n",
    "\n",
    "\n",
    "    for i in ids[size]:\n",
    "        f = find_graph_data_by_pk(p_alias, size, i)\n",
    "        \n",
    "        debug_count += 1\n",
    "        if debug == True and debug_count > 1:\n",
    "            break\n",
    "\n",
    "        nodes, graph_data = parse_graph_to_str_el(f)\n",
    "\n",
    "        image, coordinates = prepare_data(p_alias, size, i)\n",
    "            \n",
    "        content = generate_prompt_q3(modality, True, task, image, coordinates, graph_data)\n",
    "        if not virtual: \n",
    "            tasks.append(create_completion(session, content, modality, p_alias, model, size, i, task, True, debug=debug))\n",
    "        else:\n",
    "            v_c = v_completion(content, model)\n",
    "            tasks.append(v_c)\n",
    "            if console:\n",
    "                print(v_c)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd280a-57b4-43c5-a4fa-5255c96a8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def do_major_task(d_p_aliases:list=None, d_modalities:list=None, d_ids:list=None, d_model=None, d_size=None, d_tasks:list=None, debug=False, virtual=True, console=True):\n",
    "\n",
    "    p_aliases = [\"Cycle\", \"Grid\", \"Path\", \"Star\", \"SBM\"]\n",
    "    fmts = [\"edge_list\"]\n",
    "    models = [\"gpt-4o-2024-11-20\", \"gemini-2.0-flash-001\"]\n",
    "    sizes = [\"small\", \"exlarge\"]\n",
    "    modalities = [\"image\",\"data+pos\",\"image+data+pos\"]\n",
    "    tasks = [\"edge\", \"distance\"]\n",
    "    potential_tasks = [\"edge\", \"distance\", \"community\"]\n",
    "\n",
    "    if d_model != None:\n",
    "        if d_model not in models:\n",
    "            raise CustomError(f\"Invalid d_model {d_model}.\")\n",
    "        else:\n",
    "            models = [d_model]\n",
    "\n",
    "    if d_size != None:\n",
    "        if d_size not in sizes:\n",
    "            raise CustomError(f\"Invalid d_size {d_size}.\")\n",
    "        else:\n",
    "            sizes = [d_size]\n",
    "\n",
    "    if d_tasks != None:\n",
    "        for d_req in d_tasks:\n",
    "            if d_req not in potential_tasks:\n",
    "                raise CustomError(f\"Invalid tasks {d_tasks}, which {d_req} not in {potential_tasks}.\")\n",
    "            if d_req == \"community\" and d_p_aliases[0] != \"clustered graph\" and len(d_p_aliases) != 1:\n",
    "                raise CustomError(\"Invalid requirement community for non-clustered graph.\")\n",
    "        tasks = d_tasks\n",
    "\n",
    "    if d_p_aliases != None:\n",
    "        for d_p_alias in d_p_aliases:\n",
    "            if d_p_alias not in p_aliases:\n",
    "                raise CustomError(f\"Invalid p_alias {d_p_alias}, which not in {p_aliases}.\")\n",
    "        p_aliases = d_p_aliases\n",
    "\n",
    "    if d_modalities != None:\n",
    "        for d_modality in d_modalities:\n",
    "            if d_modality not in modalities:\n",
    "                raise CustomError(f\"Invalid d_modality {d_modality}, which not in {modalities}.\")\n",
    "        modalities = d_modalities\n",
    "\n",
    " \n",
    "    timeout_seconds = 180\n",
    "    session_timeout = aiohttp.ClientTimeout(total=None,sock_connect=timeout_seconds,sock_read=timeout_seconds)\n",
    "    coroutines = []\n",
    "    async with aiohttp.ClientSession(timeout=session_timeout)as session:\n",
    "        for p_alias in p_aliases:\n",
    "            term = \"general\" if p_alias == \"SBM\" else \"special\"\n",
    "            ids = dict()\n",
    "            ex_ids = extract_ids(f\"data/exlarge_{term}_graphs/edge_list/{p_alias}\")\n",
    "            s_ids = extract_ids(f\"data/small_{term}_graphs/edge_list/{p_alias}\")\n",
    "\n",
    "            ids[\"exlarge\"] = ex_ids\n",
    "            ids[\"small\"] = s_ids\n",
    "\n",
    "            if d_ids != None:\n",
    "                ids[\"exlarge\"] = sorted(d_ids)\n",
    "                ids[\"small\"] = sorted(d_ids)\n",
    "    \n",
    "            test_pks = list(product(models, sizes, modalities, tasks))\n",
    "            if d_tasks == None and p_alias == \"SBM\":\n",
    "                test_pks.extend(list(product(models, sizes, modalities, [\"community\"])))\n",
    "            for test_pk in test_pks:\n",
    "                coroutines.extend(await perform_test(session, test_pk, \n",
    "                                                p_alias=p_alias, ids=ids, \n",
    "                                                debug=debug, virtual=virtual, console=console))\n",
    "        if not console:\n",
    "                print(f\"Request count {len(coroutines)}.\")\n",
    "        if not virtual:\n",
    "            results = await asyncio.gather(*coroutines)\n",
    "\n",
    "            failed_requests = [res for res in results if \"error\" in res]\n",
    "            with open(RETRY_FILE, \"w\") as f:\n",
    "                f.write(\"\")\n",
    "            for req in failed_requests:\n",
    "                model, p_alias, size, i, task, modality = req[\"PK\"] \n",
    "                with open(RETRY_FILE, \"a\") as f:\n",
    "                    f.write(f\"Faild,{task},{p_alias}_{size}_{i}_{modality}_results.txt\\n\")\n",
    "            logging.info(f\"Failed Requests: {failed_requests}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591821f-289b-4807-848a-53acb2f4ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_q3(input_modality:str, is_global:bool, task:str, image=None, coordinates:list=None, graphdata:str=None, **kwargs):\n",
    "\n",
    "    if type(is_global) != bool:\n",
    "        raise CustomError(f\"IS_GLOBAL must be bool, now {type(is_global)}.\")\n",
    "    \n",
    "    match input_modality:\n",
    "        case \"image\":\n",
    "            if image is None:\n",
    "                raise CustomError(\"Input image is None when input_modality set to \\\"image\\\".\")\n",
    "        case \"data+pos\":\n",
    "            if coordinates is None or type(coordinates) != list:\n",
    "                raise CustomError(\"Invalid input coordinates when input_modality set to \\\"data+pos\\\"\")\n",
    "            if graphdata is None or type(graphdata) != str:\n",
    "                raise CustomError(\"Invalid input graphdata when input_modality set to \\\"data+pos\\\"\")\n",
    "        case \"image+data+pos\":\n",
    "            if image is None:\n",
    "                raise CustomError(\"Input image is None when input_modality set to \\\"image+data+pos\\\".\")\n",
    "            if coordinates is None or type(coordinates) != list:\n",
    "                raise CustomError(\"Invalid input coordinates when input_modality set to \\\"image+data+pos\\\"\")\n",
    "            if graphdata is None or type(graphdata) != str:\n",
    "                raise CustomError(\"Invalid input graphdata when input_modality set to \\\"image+data+pos\\\"\")\n",
    "        case _:\n",
    "            raise CustomError(f\"Invalid input_modality {input_modality}\")        \n",
    "    \n",
    "    if is_global:\n",
    "        match task:\n",
    "            case \"edge\":\n",
    "                s_q = \"Which has the fewest number of edge crossings?\"\n",
    "                s_answer = \"Answer 1 or 2. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "                s_input = \"\\n<edge_data>\"\n",
    "            case \"distance\":\n",
    "                s_q = \"Which better preserves graph-theoretic distance?\"\n",
    "                s_answer = \"Answer 1 or 2. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "                s_input = \"\\n<subgraph_data>\"\n",
    "            case \"community\":\n",
    "                s_q = \"Which keeps the community structure visually clearer\"\n",
    "                s_answer = \"Answer 1 or 2. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "                s_input = \"\\n<graph_layout>\"\n",
    "            case _:\n",
    "                raise CustomError(f\"TASK must be one of [\\\"edge\\\", \\\"distance\\\", \\\"community\\\"]\")\n",
    "    \n",
    "        match input_modality:\n",
    "            case \"image\":\n",
    "                s_input_instruction = \"image\"\n",
    "                s_input = \"\"\n",
    "                s_graphdata = \"\"\n",
    "                s_pos = \"\"\n",
    "            case \"data+pos\":\n",
    "                s_input_instruction = \"graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\\n{coordinates[1]}\"\n",
    "            case \"image+data+pos\":\n",
    "                s_input_instruction = \"image, graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\\n{coordinates[1]}\"\n",
    "            case _:\n",
    "                raise CustomError(f\"Invalid input_modality {input_modality}\")\n",
    "    \n",
    "        prompt = f\"Given two layouts of a graph in the {s_input_instruction} format. {s_q} {s_answer}{s_input}{s_graphdata}{s_pos}\"\n",
    "    else:\n",
    "        match input_modality:\n",
    "            case \"image\":\n",
    "                s_input_instruction = \"image\"\n",
    "                s_graphdata = \"\"\n",
    "                s_pos = \"\"\n",
    "            case \"data+pos\":\n",
    "                s_input_instruction = \"graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\"\n",
    "            case \"image+data+pos\":\n",
    "                s_input_instruction = \"image, graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\"\n",
    "            case _:\n",
    "                raise CustomError(f\"Invalid input_modality {input_modality}\")\n",
    "\n",
    "        match task:\n",
    "            case \"edge\":\n",
    "                s_q = f\"Given two edges in {s_input_instruction} format , determine whether they intersect. Answer either \\\"Yes\\\" or \\\"No\\\".\"\n",
    "                s_input = \"\\n<edge_data>\"\n",
    "                s_anwer = \"\\nPut your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "            case \"distance\":\n",
    "                source, destination = kwargs[\"source\"], kwargs[\"destination\"]\n",
    "                s_q = f\"Given a subgraph in {s_input_instruction} format. For the specified source node {source} and target node {destination} , assess whether maintains the consistency between Euclidean distance and graph theoretic distance.\" \n",
    "                s_input = \"\\n<subgraph_data>\"\n",
    "                s_anwer = \"\\nAnswer \\\"Euclidean distance is greater than graph-theoretic distance\\\", or\\\"Euclidean distance equals to graph-theoretic distance\\\" or \\\"Euclidean distance is less than graph-theoretic distance.\"\\\n",
    "                \" Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "            case \"community\":\n",
    "                s_q = f\"Given a clustered graph layout in {s_input_instruction} format,  infer the number of visible communities.\"\n",
    "                s_input = \"\\n<graph_layout>\"\n",
    "                s_anwer = \"\\nYour answer shall be an Integer. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "            case _:\n",
    "                raise CustomError(f\"TASK must be one of [\\\"edge\\\", \\\"distance\\\", \\\"community\\\"]\")\n",
    "        \n",
    "        if input_modality == \"image\":\n",
    "            s_input = \"\"\n",
    "\n",
    "        prompt = f\"{s_q}{s_input}{s_graphdata}{s_pos}{s_anwer}\"\n",
    "    \n",
    "    \n",
    "    content = [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "        }]\n",
    "    \n",
    "    if input_modality == \"image\" or input_modality == \"image+data+pos\":\n",
    "        if is_global:\n",
    "            if type(image) != list:\n",
    "                raise CustomError(\"Two images expected.\")\n",
    "            content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image[0]}\"},\n",
    "                    \"detail\": \"high\",\n",
    "                })\n",
    "            content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image[1]}\"},\n",
    "                    \"detail\": \"high\",\n",
    "                })\n",
    "        else:\n",
    "            if type(image) != str:\n",
    "                raise CustomError(\"Only 1 image expected.\")\n",
    "            content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image}\"},\n",
    "                    \"detail\": \"high\",\n",
    "                })\n",
    "\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e2a3ad-0404-4f9b-90ca-912c520a6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result(rs, storage_file):\n",
    "    result_data = rs\n",
    "\n",
    "    with open(storage_file, \"w+\") as f:\n",
    "        f.write(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c372f5-73ee-48cd-91bf-ac88b1713ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_completion(session, content:list, modality:str, p_alias:str, model:str, size:str, i:int, task:int, is_gloabl:bool, debug=False, attempt=1, official=False):\n",
    "    \n",
    "    s_gloabl = \"global\" if is_gloabl else \"local\"\n",
    "    \n",
    "    if debug == False:\n",
    "        dir_path = f\"results_{s_gloabl}/{model}/{size}/{p_alias}/{task}/{modality}\" # modify structure if inappropriate\n",
    "        full_res_dir_path = f\"full_reses_{s_gloabl}/{model}/{size}/{p_alias}/{task}/{modality}\"\n",
    "    elif debug == True:\n",
    "        dir_path = f\"results_{s_gloabl}-debug/{model}/{size}/{p_alias}/{task}/{modality}\"\n",
    "        full_res_dir_path = f\"full_reses_{s_gloabl}-debug/{model}/{size}/{p_alias}/{task}/{modality}\"\n",
    "    \n",
    "    model_url, key = get_next_endpoint_and_key()\n",
    "\n",
    "    headers = headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    model_alias = \"deepseek-chat\" if model == \"deepseek-v3\" else model\n",
    "\n",
    "    payload = {\n",
    "                \"model\": model_alias,\n",
    "                \"max_tokens\": 8000,\n",
    "                \"temperature\": 0,\n",
    "                \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }],\n",
    "                }\n",
    "    \n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    os.makedirs(full_res_dir_path, exist_ok=True)\n",
    "\n",
    "    \n",
    "    storage_path = f\"{dir_path}/{p_alias}_{size}_{i}_{task}_results.txt\"\n",
    "    full_res_path = f\"{full_res_dir_path}/{p_alias}_{size}_{i}_{task}_results.json\"\n",
    "    \n",
    "    async with SEMAPHORE:\n",
    "        try:\n",
    "            async with session.post(\n",
    "                url=f\"{model_url}/v1/chat/completions\",\n",
    "                json=payload,\n",
    "                headers=headers\n",
    "            ) as response:\n",
    "                if response.status == 200:\n",
    "                    no_exception = True\n",
    "                    buffer = []\n",
    "                    async for line in response.content:\n",
    "                        text = line.decode(\"utf-8\").strip()\n",
    "                        if text:\n",
    "                            buffer.append(text)\n",
    "                    full_response = \"\\n\".join(buffer)\n",
    "                    try:\n",
    "                        result = js.loads(full_response)\n",
    "                    except js.JSONDecodeError as e:\n",
    "                        no_exception = False\n",
    "                        logging.warning(f\"JSONDecodeError: {e}, {p_alias}, {model}, {size}, {i}, {task}, {modality}\")\n",
    "                        if attempt < MAX_RETRIES:\n",
    "                            await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                        else:\n",
    "                            logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                            return {\"error\": \"None response\", \"PK\": (model, p_alias, size, i, task, modality), \"attempts\": attempt}\n",
    "                    if no_exception:\n",
    "                        with open(full_res_path, \"w\") as f:\n",
    "                            js.dump(result, f)\n",
    "                        try:\n",
    "                            finish_reason = result['choices'][0]['finish_reason']\n",
    "                            if finish_reason == \"stop\":\n",
    "                                rs = result['choices'][0]['message']['content']\n",
    "                                parse_result(rs, storage_path)\n",
    "                            elif model == \"gpt-4o-2024-11-20\" and finish_reason == \"content_filter\":\n",
    "                                raise CustomError(\"Content filtered.\")\n",
    "                            else:\n",
    "                                no_exception = False\n",
    "                                print(finish_reason, f\"{model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                                return {\"error\": finish_reason, \"PK\": (model, p_alias, size, i, task, modality), \"attempts\": attempt}\n",
    "                        except TypeError as e:\n",
    "                            no_exception = False\n",
    "                            logging.warning(f\"{e}, {model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                            if attempt < MAX_RETRIES:\n",
    "                                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                            else:\n",
    "                                logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                                return {\"error\": \"No content in response\", \"PK\": (model, p_alias, size, i, task, modality), \"attempts\": attempt}\n",
    "                        except CustomError as e:\n",
    "                            no_exception = False\n",
    "                            logging.warning(f\"Content filtered: {model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                            if os.path.isfile(storage_path):\n",
    "                                os.remove(storage_path)\n",
    "                            if official or attempt >= MAX_RETRIES:\n",
    "                                logging.error(f\"Request failed for content filtered: {model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                                return {\"error\": str(e), \"PK\": (model, p_alias, size, i, task, modality), \"attempts\": attempt}\n",
    "                            else:\n",
    "                                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                    if no_exception:\n",
    "                        parse_result(rs, storage_path)\n",
    "                        return {\"Success\": (model, p_alias, size, i, task, modality)}\n",
    "                else:\n",
    "                    logging.warning(f\"Attempt  {model}, {p_alias}, {size}, {i}, {task}, {modality}, failed for {response.status}\")\n",
    "\n",
    "                    if attempt < MAX_RETRIES:\n",
    "                        await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                    else:\n",
    "                        logging.error(f\"Request failed after {MAX_RETRIES} attempts:  {model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                        return {\"error\": \"MAX_RETRY\", \"PK\": (model, p_alias, size, i, task, modality), \"attempts\": attempt}\n",
    "        except (aiohttp.ClientError, asyncio.TimeoutError) as e:\n",
    "            logging.warning(f\"Attempt  {model}, {p_alias}, {size}, {i}, {task}, {modality}, excepts for {e}\")\n",
    "\n",
    "            if attempt < MAX_RETRIES:\n",
    "                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "            else:\n",
    "                logging.error(f\"Request failed after {MAX_RETRIES} attempts:  {model}, {p_alias}, {size}, {i}, {task}, {modality}\")\n",
    "                return {\"error\": str(e), \"PK\": (model, p_alias, size, i, task, modality), \"attempts\": attempt}\n",
    "    return await create_completion(session, content, modality, p_alias, model, size, i, task, True, debug, attempt+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e2efab-3cf8-489e-a081-be2f71051e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_completion(content:list, model: str):\n",
    "    model_alias = \"deepseek-chat\" if model == \"deepseek-v3\" else model\n",
    "\n",
    "    json={\n",
    "        \"model\": model_alias,\n",
    "        \"max_tokens\": 8000,\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": content\n",
    "    }],\n",
    "        }\n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage:\n",
    "await do_major_task(d_p_aliases=[\"Path\"], debug=False, virtual=True, console=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
