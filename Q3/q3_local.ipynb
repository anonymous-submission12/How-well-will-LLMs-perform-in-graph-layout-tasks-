{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ff773-ea3c-44f1-af96-5f2088831324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import json as js\n",
    "import glob\n",
    "import re\n",
    "import base64\n",
    "from itertools import product\n",
    "from itertools import cycle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aade1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomError(RuntimeError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c5586-f485-48e0-961f-3a7f8523de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = Path(\"logs/async_requests.log\")\n",
    "log_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, mode=\"a\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 3 #DELAY BY SECONDS\n",
    "\n",
    "RETRY_FILE = \"retry_gpt_local.txt\"\n",
    "\n",
    "SEMAPHORE = asyncio.Semaphore(50) # Decrease if toooo big\n",
    "\n",
    "endpoints = \"YOUR END POINTS\"\n",
    "api_keys = \"YOUR API KEY\"\n",
    "\n",
    "endpoint_cycle = cycle(endpoints)\n",
    "api_key_cycle = cycle(api_keys)\n",
    "\n",
    "def get_next_endpoint_and_key():\n",
    "    return next(endpoint_cycle), next(api_key_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa00447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ids(directory):\n",
    "    integers = set()\n",
    "    pattern = re.compile(r'^(\\d+)_')\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            integers.add(int(match.group(1)))\n",
    "    \n",
    "    return sorted(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056fa75-c08a-4f57-b1a1-3acf526d6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_graph_data_by_pk(task:str, index:int) -> str:\n",
    "    match task:\n",
    "        case \"edge\":\n",
    "            home_dir = \"detailed_task_1\"\n",
    "        case \"distance\":\n",
    "            home_dir = \"detailed_task_2\"\n",
    "        case \"community\":\n",
    "            home_dir = \"detailed_task_3\"\n",
    "\n",
    "    str_pattern = f\"{index}_*.txt\"\n",
    "    files = glob.glob(f\"{home_dir}/data/{str_pattern}\")\n",
    "\n",
    "    for file in files:\n",
    "        match = re.match(rf\"{home_dir}/data/(\\d+)_.*\\.txt$\", file)\n",
    "        if match and int(match.group(1)) == index:\n",
    "            return file\n",
    "\n",
    "    raise CustomError(f\"Filename not found for {task} {index}\")\n",
    "\n",
    "def find_SD_by_pk(index:int):\n",
    "    home_dir = \"detailed_task_2\"\n",
    "\n",
    "    str_pattern = f\"{index}_*.txt\"\n",
    "    files = glob.glob(f\"{home_dir}/data/{str_pattern}\")\n",
    "\n",
    "    for file in files:\n",
    "        match = re.match(rf\"{home_dir}/data/(\\d+)_.*\\.txt$\", file)\n",
    "        if match and int(match.group(1)) == index:\n",
    "            filename =  file\n",
    "            break\n",
    "\n",
    "    matches = re.findall(r'(\\d+)', filename)\n",
    "\n",
    "    if len(matches) >= 2:\n",
    "        last_two_numbers = list(map(int, matches[-2:]))\n",
    "        return last_two_numbers\n",
    "    else:\n",
    "        raise CustomError(\"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522174c-1f97-4147-8e77-5d82f60792d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph_from_edge_list(filename:str):\n",
    "    edges = []\n",
    "    nodes = set()\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            node1, node2 = map(int, line.split())\n",
    "            \n",
    "            edges.append((node1, node2))\n",
    "            \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "    \n",
    "    return sorted(list(nodes)), sorted(list(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dca9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_alias(pattern: str) -> str:\n",
    "    if pattern not in [\"Cycle\",\"Star\", \"Path\", \"Grid\", \"clustered graph\"]:\n",
    "        raise CustomError(f\"Invalid pattern {pattern}\")\n",
    "    if pattern == \"clustered graph\":\n",
    "        p_alias = \"SBM\"\n",
    "    else:\n",
    "        p_alias = pattern\n",
    "    return p_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ac64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def prepare_data(task:str, i:int):\n",
    "    match task:\n",
    "        case \"edge\":\n",
    "            home_dir = \"detailed_task_1\"\n",
    "        case \"distance\":\n",
    "            home_dir = \"detailed_task_2\"\n",
    "        case \"community\":\n",
    "            home_dir = \"detailed_task_3\"\n",
    "\n",
    "    for filename in os.listdir(f\"{home_dir}/images\"):\n",
    "        if filename.startswith(f\"{i}\"):\n",
    "            i_path = os.path.join(f\"{home_dir}/images\", filename)\n",
    "            break\n",
    "\n",
    "    for filename in os.listdir(f\"{home_dir}/layouts\"):\n",
    "        if filename.startswith(f\"{i}\"):\n",
    "            p_path = os.path.join(f\"{home_dir}/layouts\", filename)\n",
    "            break\n",
    "    image = encode_image(i_path)\n",
    "    \n",
    "    with open(p_path, \"r\") as f:\n",
    "        p1 = js.load(f)\n",
    "    pos = [p1]\n",
    "\n",
    "    return image, pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c2d3d-5cb9-461e-9458-a43e27faf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_graph_to_str_el(f):\n",
    "    n, e = read_graph_from_edge_list(f)\n",
    "    return n, str(e)\n",
    "\n",
    "async def perform_test(session, test_pks:list, ids:list, debug=False, virtual=True, console=True):\n",
    "    tasks = []\n",
    "    valid_requirements = [\"edge\", \"distance\", \"community\"]\n",
    "    \n",
    "    debug_count = 0\n",
    "    model, modality, task = test_pks\n",
    "\n",
    "    if task not in valid_requirements:\n",
    "        raise CustomError(f\"Invalid requirement {task}.\")\n",
    "\n",
    "\n",
    "    for i in ids:\n",
    "        f = find_graph_data_by_pk(task, i)\n",
    "        source, destination = find_SD_by_pk(i)\n",
    "        \n",
    "        debug_count += 1\n",
    "        if debug == True and debug_count > 1:\n",
    "            break\n",
    "\n",
    "        nodes, graph_data = parse_graph_to_str_el(f)\n",
    "\n",
    "        image, coordinates = prepare_data(task, i)\n",
    "            \n",
    "        content = generate_prompt_q3(modality, False, task, image, coordinates, graph_data, source=source, destination=destination)\n",
    "        if not virtual: \n",
    "            tasks.append(create_completion(session, content, modality, model, i, task, False, debug=debug))\n",
    "        else:\n",
    "            v_c = v_completion(content, model)\n",
    "            tasks.append(v_c)\n",
    "            if console:\n",
    "                print(v_c)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd280a-57b4-43c5-a4fa-5255c96a8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def do_minor_task(d_modalities:list=None, d_ids:list=None, d_model=None, d_tasks:list=None, debug=False, virtual=True, console=True):\n",
    "\n",
    "    fmts = [\"edge_list\"]\n",
    "    models = [\"gpt-4o-2024-11-20\", \"gemini-2.0-flash-001\"]\n",
    "    modalities = [\"image\",\"data+pos\",\"image+data+pos\"]\n",
    "    potential_tasks = [\"edge\", \"distance\", \"community\"]\n",
    "    tasks = potential_tasks\n",
    "\n",
    "    if d_model != None:\n",
    "        if d_model not in models:\n",
    "            raise CustomError(f\"Invalid d_model {d_model}.\")\n",
    "        else:\n",
    "            models = [d_model]\n",
    "\n",
    "    if d_tasks != None:\n",
    "        for d_req in d_tasks:\n",
    "            if d_req not in potential_tasks:\n",
    "                raise CustomError(f\"Invalid tasks {d_tasks}, which {d_req} not in {potential_tasks}.\")\n",
    "            tasks = d_tasks\n",
    "\n",
    "    if d_modalities != None:\n",
    "        for d_modality in d_modalities:\n",
    "            if d_modality not in modalities:\n",
    "                raise CustomError(f\"Invalid d_modality {d_modality}, which not in {modalities}.\")\n",
    "        modalities = d_modalities\n",
    "\n",
    " \n",
    "    timeout_seconds = 180\n",
    "    session_timeout = aiohttp.ClientTimeout(total=None,sock_connect=timeout_seconds,sock_read=timeout_seconds)\n",
    "    coroutines = []\n",
    "    async with aiohttp.ClientSession(timeout=session_timeout)as session:\n",
    "        ids = list(range(0, 10))\n",
    "    \n",
    "        test_pks = list(product(models, modalities, tasks))\n",
    "        for test_pk in test_pks:\n",
    "            coroutines.extend(await perform_test(session, test_pk, \n",
    "                                                ids=ids, debug=debug, virtual=virtual, console=console))\n",
    "        if not console:\n",
    "                print(f\"Request count {len(coroutines)}.\")\n",
    "        if not virtual:\n",
    "            results = await asyncio.gather(*coroutines)\n",
    "\n",
    "            failed_requests = [res for res in results if \"error\" in res]\n",
    "            with open(RETRY_FILE, \"w\") as f:\n",
    "                f.write(\"\")\n",
    "            for req in failed_requests:\n",
    "                model, i, task, modality = req[\"PK\"] \n",
    "                with open(RETRY_FILE, \"a\") as f:\n",
    "                    f.write(f\"Faild,{task},{i}_{modality}_results.txt\\n\")\n",
    "            logging.info(f\"Failed Requests: {failed_requests}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591821f-289b-4807-848a-53acb2f4ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_q3(input_modality:str, is_global:bool, task:str, image=None, coordinates:list=None, graphdata:str=None, **kwargs):\n",
    "\n",
    "    if type(is_global) != bool:\n",
    "        raise CustomError(f\"IS_GLOBAL must be bool, now {type(is_global)}.\")\n",
    "    \n",
    "    match input_modality:\n",
    "        case \"image\":\n",
    "            if image is None:\n",
    "                raise CustomError(\"Input image is None when input_modality set to \\\"image\\\".\")\n",
    "        case \"data+pos\":\n",
    "            if coordinates is None or type(coordinates) != list:\n",
    "                raise CustomError(\"Invalid input coordinates when input_modality set to \\\"data+pos\\\"\")\n",
    "            if graphdata is None or type(graphdata) != str:\n",
    "                raise CustomError(\"Invalid input graphdata when input_modality set to \\\"data+pos\\\"\")\n",
    "        case \"image+data+pos\":\n",
    "            if image is None:\n",
    "                raise CustomError(\"Input image is None when input_modality set to \\\"image+data+pos\\\".\")\n",
    "            if coordinates is None or type(coordinates) != list:\n",
    "                raise CustomError(\"Invalid input coordinates when input_modality set to \\\"image+data+pos\\\"\")\n",
    "            if graphdata is None or type(graphdata) != str:\n",
    "                raise CustomError(\"Invalid input graphdata when input_modality set to \\\"image+data+pos\\\"\")\n",
    "        case _:\n",
    "            raise CustomError(f\"Invalid input_modality {input_modality}\")        \n",
    "    \n",
    "    if is_global:\n",
    "        match task:\n",
    "            case \"edge\":\n",
    "                s_q = \"Which has the fewest number of edge crossings?\"\n",
    "                s_answer = \"Answer 1 or 2. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "                s_input = \"\\n<edge_data>\"\n",
    "            case \"distance\":\n",
    "                s_q = \"Which better preserves graph-theoretic distance?\"\n",
    "                s_answer = \"Answer 1 or 2. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "                s_input = \"\\n<subgraph_data>\"\n",
    "            case \"community\":\n",
    "                s_q = \"Which keeps the community structure visually clearer\"\n",
    "                s_answer = \"Answer 1 or 2. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "                s_input = \"\\n<graph_layout>\"\n",
    "            case _:\n",
    "                raise CustomError(f\"TASK must be one of [\\\"edge\\\", \\\"distance\\\", \\\"community\\\"]\")\n",
    "    \n",
    "        match input_modality:\n",
    "            case \"image\":\n",
    "                s_input_instruction = \"image\"\n",
    "                s_input = \"\"\n",
    "                s_graphdata = \"\"\n",
    "                s_pos = \"\"\n",
    "            case \"data+pos\":\n",
    "                s_input_instruction = \"graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\\n{coordinates[1]}\"\n",
    "            case \"image+data+pos\":\n",
    "                s_input_instruction = \"image, graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\\n{coordinates[1]}\"\n",
    "            case _:\n",
    "                raise CustomError(f\"Invalid input_modality {input_modality}\")\n",
    "    \n",
    "        prompt = f\"Given two layouts of a graph in the {s_input_instruction} format. {s_q} {s_answer}{s_input}{s_graphdata}{s_pos}\"\n",
    "    else:\n",
    "        match input_modality:\n",
    "            case \"image\":\n",
    "                s_input_instruction = \"image\"\n",
    "                s_graphdata = \"\"\n",
    "                s_pos = \"\"\n",
    "            case \"data+pos\":\n",
    "                s_input_instruction = \"graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\"\n",
    "            case \"image+data+pos\":\n",
    "                s_input_instruction = \"image, graph data and node coordinates\"\n",
    "                s_graphdata = f\"\\n{graphdata}\"\n",
    "                s_pos = f\"\\n{coordinates[0]}\"\n",
    "            case _:\n",
    "                raise CustomError(f\"Invalid input_modality {input_modality}\")\n",
    "\n",
    "        match task:\n",
    "            case \"edge\":\n",
    "                s_q = f\"Given two edges in {s_input_instruction} format, determine whether they intersect. Answer either \\\"Yes\\\" or \\\"No\\\".\"\n",
    "                s_input = \"\\n<edge_data>\"\n",
    "                s_anwer = \"\\nPut your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "            case \"distance\":\n",
    "                source, destination = kwargs[\"source\"], kwargs[\"destination\"]\n",
    "                s_q = f\"Given a subgraph in {s_input_instruction} format. For the specified source node {source} and target node {destination}, assess whether maintains the consistency between Euclidean distance and graph theoretic distance.\" \n",
    "                s_input = \"\\n<subgraph_data>\"\n",
    "                s_anwer = \"\\nAnswer \\\"Euclidean distance is greater than graph-theoretic distance\\\", or\\\"Euclidean distance equals to graph-theoretic distance\\\" or \\\"Euclidean distance is less than graph-theoretic distance.\"\\\n",
    "                \" Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "            case \"community\":\n",
    "                s_q = f\"Given a graph layout with community structures in {s_input_instruction} format, estimate the number of communities based on spatial clustering patterns.\"\n",
    "                s_input = \"\\n<graph_layout>\"\n",
    "                s_anwer = \"\\nYour answer shall be an Integer. Put your final answer in a json block, use a field \\\"Answer\\\" to present your answer.\"\n",
    "            case _:\n",
    "                raise CustomError(f\"TASK must be one of [\\\"edge\\\", \\\"distance\\\", \\\"community\\\"]\")\n",
    "        \n",
    "        if input_modality == \"image\":\n",
    "            s_input = \"\"\n",
    "\n",
    "        prompt = f\"{s_q}{s_input}{s_graphdata}{s_pos}{s_anwer}\"\n",
    "    \n",
    "    \n",
    "    content = [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "        }]\n",
    "    \n",
    "    if input_modality == \"image\" or input_modality == \"image+data+pos\":\n",
    "        if is_global:\n",
    "            if type(image) != list:\n",
    "                raise CustomError(\"Two images expected.\")\n",
    "            content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image[0]}\"},\n",
    "                    \"detail\": \"high\",\n",
    "                })\n",
    "            content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image[1]}\"},\n",
    "                    \"detail\": \"high\",\n",
    "                })\n",
    "        else:\n",
    "            if type(image) != str:\n",
    "                raise CustomError(\"Only 1 image expected.\")\n",
    "            content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image}\"},\n",
    "                    \"detail\": \"high\",\n",
    "                })\n",
    "\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e2a3ad-0404-4f9b-90ca-912c520a6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result(rs, storage_file):\n",
    "    result_data = rs\n",
    "\n",
    "    with open(storage_file, \"w+\") as f:\n",
    "        f.write(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c372f5-73ee-48cd-91bf-ac88b1713ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_completion(session, content:list, modality:str, model:str, i:int, task:int, is_gloabl:bool, debug=False, attempt=1):\n",
    "    \n",
    "    s_gloabl = \"global\" if is_gloabl else \"local\"\n",
    "    \n",
    "    if debug == False:\n",
    "        dir_path = f\"results_{s_gloabl}/{model}/{task}/{modality}\" # modify structure if inappropriate\n",
    "        full_res_dir_path = f\"full_reses_{s_gloabl}/{model}/{task}/{modality}\"\n",
    "    elif debug == True:\n",
    "        dir_path = f\"results_{s_gloabl}-debug/{model}/{task}/{modality}\"\n",
    "        full_res_dir_path = f\"full_reses_{s_gloabl}-debug/{model}/{task}/{modality}\"\n",
    "    \n",
    "    model_url, key = get_next_endpoint_and_key()\n",
    "\n",
    "    headers = headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    model_alias = \"deepseek-chat\" if model == \"deepseek-v3\" else model\n",
    "\n",
    "    payload = {\n",
    "                \"model\": model_alias,\n",
    "                \"max_tokens\": 8000,\n",
    "                \"temperature\": 0,\n",
    "                \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }],\n",
    "                }\n",
    "    \n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    os.makedirs(full_res_dir_path, exist_ok=True)\n",
    "\n",
    "    \n",
    "    storage_path = f\"{dir_path}/{i}_{task}_results.txt\"\n",
    "    full_res_path = f\"{full_res_dir_path}/{i}_{task}_results.json\"\n",
    "    \n",
    "    async with SEMAPHORE:\n",
    "        try:\n",
    "            async with session.post(\n",
    "                url=f\"{model_url}/v1/chat/completions\",\n",
    "                json=payload,\n",
    "                headers=headers\n",
    "            ) as response:\n",
    "                if response.status == 200:\n",
    "                    no_exception = True\n",
    "                    buffer = []\n",
    "                    async for line in response.content:\n",
    "                        text = line.decode(\"utf-8\").strip()\n",
    "                        if text:\n",
    "                            buffer.append(text)\n",
    "                    full_response = \"\\n\".join(buffer)\n",
    "                    try:\n",
    "                        result = js.loads(full_response)\n",
    "                    except js.JSONDecodeError as e:\n",
    "                        no_exception = False\n",
    "                        logging.warning(f\"JSONDecodeError: {e}, {model}, {i}, {task}, {modality}\")\n",
    "                        if attempt < MAX_RETRIES:\n",
    "                            await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                        else:\n",
    "                            logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {i}, {task}, {modality}\")\n",
    "                            return {\"error\": \"None response\", \"PK\": (model, i, task, modality), \"attempts\": attempt}\n",
    "                    if no_exception:\n",
    "                        with open(full_res_path, \"w\") as f:\n",
    "                            js.dump(result, f)\n",
    "                        try:\n",
    "                            finish_reason = result['choices'][0]['finish_reason']\n",
    "                            if finish_reason == \"stop\":\n",
    "                                rs = result['choices'][0]['message']['content']\n",
    "                                parse_result(rs, storage_path)\n",
    "                            elif model == \"gpt-4o-2024-11-20\" and finish_reason == \"content_filter\":\n",
    "                                raise CustomError(\"Content filtered.\")\n",
    "                            else:\n",
    "                                no_exception = False\n",
    "                                print(finish_reason, f\"{model}, {i}, {task}, {modality}\")\n",
    "                                return {\"error\": finish_reason, \"PK\": (model, i, task, modality), \"attempts\": attempt}\n",
    "                        except TypeError as e:\n",
    "                            no_exception = False\n",
    "                            logging.warning(f\"{e}, {model}, {i}, {task}, {modality}\")\n",
    "                            if attempt < MAX_RETRIES:\n",
    "                                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                            else:\n",
    "                                logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {i}, {task}, {modality}\")\n",
    "                                return {\"error\": \"No content in response\", \"PK\": (model, i, task, modality), \"attempts\": attempt}\n",
    "                        except CustomError as e:\n",
    "                            no_exception = False\n",
    "                            logging.warning(f\"Content filtered: {model}, {i}, {task}, {modality}\")\n",
    "                            if os.path.isfile(storage_path):\n",
    "                                os.remove(storage_path)\n",
    "                            if attempt >= MAX_RETRIES:\n",
    "                                logging.error(f\"Request failed for content filtered: {model}, {i}, {task}, {modality}\")\n",
    "                                return {\"error\": str(e), \"PK\": (model, i, task, modality), \"attempts\": attempt}\n",
    "                            else:\n",
    "                                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                    if no_exception:\n",
    "                        parse_result(rs, storage_path)\n",
    "                        return {\"Success\": (model, i, task, modality)}\n",
    "                else:\n",
    "                    logging.warning(f\"Attempt  {model}, {i}, {task}, {modality}, failed for {response.status}\")\n",
    "\n",
    "                    if attempt < MAX_RETRIES:\n",
    "                        await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                    else:\n",
    "                        logging.error(f\"Request failed after {MAX_RETRIES} attempts:  {model}, {i}, {task}, {modality}\")\n",
    "                        return {\"error\": \"MAX_RETRY\", \"PK\": (model, i, task, modality), \"attempts\": attempt}\n",
    "        except (aiohttp.ClientError, asyncio.TimeoutError) as e:\n",
    "            logging.warning(f\"Attempt  {model}, {i}, {task}, {modality}, excepts for {e}\")\n",
    "\n",
    "            if attempt < MAX_RETRIES:\n",
    "                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "            else:\n",
    "                logging.error(f\"Request failed after {MAX_RETRIES} attempts:  {model}, {i}, {task}, {modality}\")\n",
    "                return {\"error\": str(e), \"PK\": (model, i, task, modality), \"attempts\": attempt}\n",
    "    return await create_completion(session, content, modality, model, i, task, False, debug, attempt+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e2efab-3cf8-489e-a081-be2f71051e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_completion(content:list, model: str):\n",
    "    model_alias = \"deepseek-chat\" if model == \"deepseek-v3\" else model\n",
    "\n",
    "    json={\n",
    "        \"model\": model_alias,\n",
    "        \"max_tokens\": 8000,\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": content\n",
    "    }],\n",
    "        }\n",
    "    return json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c70e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d3ae9-fd61-4886-8e51-87127210f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exaple usage:\n",
    "await do_minor_task(debug=False, virtual=False, console=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
