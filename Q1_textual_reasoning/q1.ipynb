{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ff773-ea3c-44f1-af96-5f2088831324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import json as js\n",
    "import glob\n",
    "import re\n",
    "from itertools import product\n",
    "from itertools import cycle\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aade1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomError(RuntimeError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c5586-f485-48e0-961f-3a7f8523de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = Path(\"logs/async_requests.log\")\n",
    "log_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, mode=\"a\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "MAX_RETRIES = 3 #MAX_ATTEMPTS in fact.\n",
    "RETRY_DELAY = 3\n",
    "\n",
    "SEMAPHORE = asyncio.Semaphore(3)\n",
    "\n",
    "endpoints = \"YOUR LIST OF ENDPOINTS\"\n",
    "api_keys = \"YOUR LIST OF APIKEYS\"\n",
    "\n",
    "endpoint_cycle = cycle(endpoints)\n",
    "api_key_cycle = cycle(api_keys)\n",
    "\n",
    "def get_next_endpoint_and_key():\n",
    "    raise NotImplementedError()\n",
    "    #return next(endpoint_cycle), next(api_key_cycle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ids(directory: str):\n",
    "    \"\"\"Extract graph data IDs from DIRECTORY\"\"\"\n",
    "    integers = set()\n",
    "    pattern = re.compile(r'^(\\d+)_')\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            integers.add(int(match.group(1)))\n",
    "    \n",
    "    return sorted(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056fa75-c08a-4f57-b1a1-3acf526d6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_graph_data_by_pk(fmt:str, p_alias:str, size:str, index:int) -> str:\n",
    "    \"\"\"Find the path of graph data file for (FMT, P_ALIAS, SIZE, INDEX)\"\"\"\n",
    "    if size not in [\"small\", \"exlarge\"]:\n",
    "        raise CustomError(f\"Invalid size {size}.\")\n",
    "    if fmt not in [\"adjacency_list\", \"edge_list\"]:\n",
    "        raise CustomError(f\"Invalid fmt {fmt}.\")\n",
    "\n",
    "    term = \"general\" if p_alias == \"SBM\" else \"special\"\n",
    "\n",
    "    str_pattern = f\"{index}_{p_alias}_*.txt\"\n",
    "    files = glob.glob(f\"data/{size}_{term}_graphs/{fmt}/{p_alias}/{str_pattern}\")\n",
    "\n",
    "    for file in files:\n",
    "        match = re.match(rf\"data/{size}_{term}_graphs/{fmt}/{p_alias}/(\\d+)_.*\\.txt$\", file)\n",
    "        if match and int(match.group(1)) == index:\n",
    "            return file\n",
    "    \n",
    "    raise CustomError(f\"Filename not found for {fmt} {p_alias} {size} {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522174c-1f97-4147-8e77-5d82f60792d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph_from_edge_list(filename:str):\n",
    "    \"\"\"Get graph data from file FILENAME, in which stores graph data in edge list. \"\"\"\n",
    "    edges = []\n",
    "    nodes = set()\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            node1, node2 = map(int, line.split())\n",
    "            \n",
    "            edges.append((node1, node2))\n",
    "            \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "    \n",
    "    return sorted(list(nodes)), sorted(list(edges))\n",
    "\n",
    "def read_graph_from_adj_list(filename:str):\n",
    "    \"\"\"Get graph data from file FILENAME, in which stores graph data in adjacency list. \"\"\"\n",
    "    edges = set()\n",
    "    nodes = set()\n",
    "    graph = {}\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            node, adj_list_str = line.split(':')\n",
    "            node = int(node.strip())\n",
    "            \n",
    "            adj_list = ast.literal_eval(adj_list_str.strip())\n",
    "            \n",
    "            graph[node] = adj_list\n",
    "\n",
    "            nodes.add(node)\n",
    "            \n",
    "            for adj_node in adj_list:\n",
    "                edge = tuple(sorted((node, adj_node)))\n",
    "                edges.add(edge)\n",
    "                nodes.add(adj_node)\n",
    "    \n",
    "    return sorted(list(nodes)), sorted(list(edges)), graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_alias(pattern: str) -> str:\n",
    "    \"\"\"Convert PATTERN into its alias. \"\"\"\n",
    "    if pattern not in [\"Cycle\",\"Star\", \"Path\", \"Grid\", \"clustered graph\"]:\n",
    "        raise CustomError(f\"Invalid pattern {pattern}\")\n",
    "    elif pattern == \"clustered graph\":\n",
    "        p_alias = \"SBM\"\n",
    "    else:\n",
    "        p_alias = pattern\n",
    "    return p_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c2d3d-5cb9-461e-9458-a43e27faf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_graph_to_str_el(f):\n",
    "    n, e = read_graph_from_edge_list(f)\n",
    "    return n, str(e)\n",
    "\n",
    "def parse_graph_to_str_al(f):\n",
    "    n, e, g = read_graph_from_adj_list(f)\n",
    "    return n, str(g)\n",
    "\n",
    "async def perform_test(session, test_pks:list, p_alias:str, ids:list, d_questions:list=None, d_pair:list=None, debug=False, virtual=False, console=True):\n",
    "    tasks = []\n",
    "    questions = [\"minor\", \"minor\", \"minor\", \"minor\"]\n",
    "    minors = [\"node_count\", \"edge_count\", \"shortest_path\", \"highest_degree\"]\n",
    "    if p_alias == \"SBM\":\n",
    "        questions.append(\"community\")\n",
    "        minors.append(None)\n",
    "    debug_count = 0\n",
    "    fmt, model, size = test_pks\n",
    "\n",
    "    q_combinations = list(zip(questions, minors))\n",
    "\n",
    "    if d_questions != None:\n",
    "        if type(d_questions) != list:\n",
    "            raise CustomError(\"d_questions must be list\")\n",
    "        for d_q in d_questions:\n",
    "            if d_q not in q_combinations:\n",
    "                raise CustomError(f\"Invalid d_question {d_q}.\")\n",
    "        q_combinations = d_questions\n",
    "\n",
    "    for i in ids[size]:\n",
    "        f = find_graph_data_by_pk(fmt, p_alias, size, i)\n",
    "\n",
    "        debug_count += 1\n",
    "        if debug == True and debug_count > 1:\n",
    "            break\n",
    "\n",
    "        if fmt == \"adjacency_list\":\n",
    "            nodes, graph_data = parse_graph_to_str_al(f)\n",
    "        else:\n",
    "            nodes, graph_data = parse_graph_to_str_el(f)\n",
    "        for q in q_combinations:\n",
    "            if q == (\"minor\", \"shortest_path\"):\n",
    "                if d_pair != None: \n",
    "                    if type(d_pair) == tuple and len(d_pair) == 2:\n",
    "                        pair = d_pair\n",
    "                    else:\n",
    "                        raise CustomError(f\"Invalid D_PAIR {d_pair}\")\n",
    "                else:\n",
    "                    pair = random.sample(nodes, 2)\n",
    "            else:\n",
    "                pair = None\n",
    "            content = generate_prompt_q1(graph_data, fmt, q[0], q[1], pair)\n",
    "            if not virtual: \n",
    "                tasks.append(create_completion(session, content, p_alias, graph_data, fmt, model, size, i, q, pair, debug=debug))\n",
    "            else:\n",
    "                v_c = v_completion(content, model)\n",
    "                tasks.append(v_c)\n",
    "                if console:\n",
    "                    print(v_c)\n",
    "\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd280a-57b4-43c5-a4fa-5255c96a8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def do_task(patterns: list, d_ids:list=None, d_fmt=None, d_model=None, d_size=None, d_questions:list=None, d_pair:list=None, debug=False, virtual=False, console=True):\n",
    "    \"\"\"Perform tests on task data determined by PATTERN.\\n\n",
    "        Parameters starting with \"d_\" are optional, use them if dimensions of the task are specified.\\n\n",
    "        Set DEBUG to True to test with a few runs.\\n\n",
    "        Set VIRTUAL to True to inspect the prompts generated without sending any actual requests.\n",
    "        Set CONSOLE to False to disable print statements.\n",
    "        \"\"\"\n",
    "    #Define task variables here\n",
    "    fmts = [\"adjacency_list\", \"edge_list\"]\n",
    "    models = [\"gpt-4o-2024-11-20\", \"deepseek-v3\", \"gemini-2.0-flash-001\"]\n",
    "    sizes = [\"exlarge\",\"small\"]\n",
    "    \n",
    "\n",
    "    if type(patterns) != list:\n",
    "        raise CustomError(\"Patterns must be list.\")\n",
    "    \n",
    "    if d_fmt != None:\n",
    "        if d_fmt not in fmts:\n",
    "            raise RuntimeError(f\"Invalid d_fmt {d_fmt}.\")\n",
    "        else:\n",
    "            fmts = [d_fmt]\n",
    "\n",
    "    if d_model != None:\n",
    "        if d_model not in models:\n",
    "            raise RuntimeError(f\"Invalid d_model {d_model}.\")\n",
    "        else:\n",
    "            models = [d_model]\n",
    "\n",
    "    if d_size != None:\n",
    "        if d_size not in sizes:\n",
    "            raise RuntimeError(f\"Invalid d_size {d_size}.\")\n",
    "        else:\n",
    "            sizes = [d_size]\n",
    "\n",
    "    timeout_seconds = 120\n",
    "    session_timeout = aiohttp.ClientTimeout(total=None,sock_connect=timeout_seconds,sock_read=timeout_seconds)\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession(timeout=session_timeout)as session:\n",
    "        for p in patterns:\n",
    "            p_alias = get_p_alias(p)\n",
    "            term = \"general\" if p_alias == \"ER\" or p_alias == \"SBM\" else \"special\"\n",
    "            ids = dict()\n",
    "            ids[\"exlarge\"] = extract_ids(f\"data/exlarge_{term}_graphs/edge_list/{p_alias}\")\n",
    "            ids[\"small\"] = extract_ids(f\"data/small_{term}_graphs/edge_list/{p_alias}\")\n",
    "\n",
    "            if d_ids != None:\n",
    "                ids[\"exlarge\"] = sorted(d_ids)\n",
    "                ids[\"small\"] = sorted(d_ids)\n",
    "    \n",
    "            test_pks = list(product(fmts, models, sizes))\n",
    "            for test_pk in test_pks:\n",
    "                tasks.extend(await perform_test(session, test_pk, p_alias, ids, d_questions, d_pair, debug, virtual, console))\n",
    "        if not console:\n",
    "                print(f\"Request count {len(tasks)}.\")\n",
    "        if not virtual:\n",
    "            results = await asyncio.gather(*tasks)\n",
    "\n",
    "            failed_requests = [res for res in results if \"error\" in res]\n",
    "            with open(\"retry.txt\", \"w\") as f:\n",
    "                f.write(\"\")\n",
    "            for req in failed_requests:\n",
    "                model, p_alias, fmt, size, i, q = req[\"PK\"] \n",
    "                with open(\"retry.txt\", \"a\") as f:\n",
    "                    f.write(f\"Faild,{q},{p_alias}_{fmt}_{size}_{i}_results.txt\\n\")\n",
    "                    \n",
    "            logging.info(f\"Failed Requests: {failed_requests}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591821f-289b-4807-848a-53acb2f4ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_q1(graph_data: str, fmt: str, question:str, minor=None, pair:list=None):\n",
    "\n",
    "    quesion_community = \"It's a graph with community structure, count the number of communities in the graph.\"\n",
    "\n",
    "    match minor:\n",
    "        case None: \n",
    "            pass\n",
    "        case \"node_count\": \n",
    "            question_minor = \"count the number of nodes in the graph.\"\n",
    "            answer_format = \"Integer\"\n",
    "        case \"edge_count\": \n",
    "            question_minor = \"count the number of edges in the graph.\"\n",
    "            answer_format = \"Integer\"\n",
    "        case \"shortest_path\":\n",
    "            if pair == None:\n",
    "                raise CustomError(\"No pair of nodes selected for shortest path!\")\n",
    "            else:\n",
    "                node0, node1 = pair\n",
    "            question_minor = f\"calculate the length of the shortest path bewteen node '{node0}' and '{node1}'.\"\n",
    "            answer_format = \"Integer\"\n",
    "        case \"highest_degree\": \n",
    "            question_minor = \"calculate the highest degree of all nodes in the graph.\"\n",
    "            answer_format = \"Integer\"\n",
    "        case _: raise CustomError(f\"Invalid minor question {minor}\")\n",
    "\n",
    "    match question:\n",
    "        case \"community\":\n",
    "            s_question = quesion_community\n",
    "            answer_format = \"Integer\"\n",
    "        case \"minor\":\n",
    "            if minor == None:\n",
    "                raise RuntimeError(\"Minor should not be None\")\n",
    "            minor = minor\n",
    "            s_question = question_minor\n",
    "        case _:\n",
    "            raise CustomError(f\"Invalid major question {question}\")\n",
    "\n",
    "    ss = f\"I will provide you a graph with the format of {fmt}, {s_question}\\n\"\\\n",
    "    f\"<graph data>\\n{graph_data}.\\n Your response shall include a JSON wrapped in a code block in which a field \\\"answer\\\" represents your answer({answer_format}).\"\n",
    "    content = [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": ss,\n",
    "        }]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e2a3ad-0404-4f9b-90ca-912c520a6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result(rs, storage_file):\n",
    "    result_data = rs\n",
    "\n",
    "    with open(storage_file, \"w+\") as f:\n",
    "        f.write(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c372f5-73ee-48cd-91bf-ac88b1713ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_completion(session, content:list, p_alias:str, graph_data:str, fmt:str, model:str, size:str, i:int, q:tuple, pair:list=None, debug=False, attempt=1):\n",
    "    if debug == False:\n",
    "        dir_path = f\"results/{model}/{size}/{fmt}/{p_alias}/{q[0]}_{q[1]}\" # modify structure if inappropriate\n",
    "        full_res_dir_path = f\"full_reses/{model}/{size}/{fmt}/{p_alias}/{q[0]}_{q[1]}\"\n",
    "    elif debug == True:\n",
    "        dir_path = f\"results-debug/{model}/{size}/{fmt}/{p_alias}/{q[0]}_{q[1]}\"\n",
    "        full_res_dir_path = f\"full_reses-debug/{model}/{size}/{fmt}/{p_alias}/{q[0]}_{q[1]}\"\n",
    "    \n",
    "    model_url, key = get_next_endpoint_and_key()\n",
    "    headers = headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    model_alias = \"deepseek-chat\" if model == \"deepseek-v3\" else model #Deepseek offcial api provides deepseek-v3 by name deepseek-chat\n",
    "    \n",
    "    payload = {\n",
    "                \"model\": model_alias,\n",
    "                \"max_completion_tokens\":8000,\n",
    "                \"temperature\": 0,\n",
    "                \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }],\n",
    "                }\n",
    "    \n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    os.makedirs(full_res_dir_path, exist_ok=True)\n",
    "    \n",
    "    major, minor = q\n",
    "    s_q = major if minor == None else f\"{major}_{minor}\"\n",
    "\n",
    "    if s_q == \"minor_shortest_path\":\n",
    "        if pair == None:\n",
    "            raise CustomError(\"No pair of nodes selected for shortest path!\")\n",
    "        else:\n",
    "            node0, node1 = pair\n",
    "            storage_path = f\"{dir_path}/{p_alias}_{fmt}_{size}_{i}_{node0}_{node1}_results.txt\"\n",
    "            full_res_path = f\"{full_res_dir_path}/{p_alias}_{fmt}_{size}_{i}_{node0}_{node1}_results.json\"\n",
    "    else:\n",
    "        storage_path = f\"{dir_path}/{p_alias}_{fmt}_{size}_{i}_results.txt\"\n",
    "        full_res_path = f\"{full_res_dir_path}/{p_alias}_{fmt}_{size}_{i}_results.json\"\n",
    "    async with SEMAPHORE:\n",
    "        try:\n",
    "            async with session.post(\n",
    "                url=f\"{model_url}/v1/chat/completions\",\n",
    "                json=payload,\n",
    "                headers=headers\n",
    "            ) as response:\n",
    "                if response.status == 200:\n",
    "                    no_exception = True\n",
    "                    buffer = []\n",
    "                    async for line in response.content:\n",
    "                        text = line.decode(\"utf-8\").strip()\n",
    "                        if text:\n",
    "                            buffer.append(text)\n",
    "                    full_response = \"\\n\".join(buffer)\n",
    "                    try:\n",
    "                        result = js.loads(full_response)\n",
    "                    except js.JSONDecodeError as e:\n",
    "                        no_exception = False\n",
    "                        if attempt < MAX_RETRIES:\n",
    "                            await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                        else:\n",
    "                            logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {p_alias}, {fmt}, {size}, {i}, {s_q}\")\n",
    "                            return {\"error\": \"None response\", \"PK\": (model, p_alias, fmt, size, i, s_q), \"attempts\": attempt}\n",
    "                    if no_exception:\n",
    "                        with open(full_res_path, \"w\") as f:\n",
    "                            js.dump(result, f)\n",
    "                        try:\n",
    "                            rs = result['choices'][0]['message']['content']\n",
    "                        except TypeError as e:\n",
    "                            no_exception = False\n",
    "                            logging.warning(f\"{e}, {p_alias}, {fmt}, {size}, {i}, {s_q}\")\n",
    "                            if attempt < MAX_RETRIES:\n",
    "                                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                            else:\n",
    "                                logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {p_alias}, {fmt}, {size}, {i}, {s_q}\")\n",
    "                                return {\"error\": \"No content in response\", \"PK\": (model, p_alias, fmt, size, i, s_q), \"attempts\": attempt}\n",
    "                    if no_exception:\n",
    "                        parse_result(rs, storage_path)\n",
    "                        return {\"Success\": (model, p_alias, fmt, size, i, s_q)}\n",
    "                else:\n",
    "                    logging.warning(f\"Attempt {model}, {p_alias}, {fmt}, {size}, {i}, {s_q}, failed for {response.status}\")\n",
    "\n",
    "                    if attempt < MAX_RETRIES:\n",
    "                        await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "                    \n",
    "                    else:\n",
    "                        logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {p_alias}, {fmt}, {size}, {i}, {s_q}\")\n",
    "                        return {\"error\": \"MAX_RETRY\", \"PK\": (model, p_alias, fmt, size, i, s_q), \"attempts\": attempt}\n",
    "        except (aiohttp.ClientError, asyncio.TimeoutError) as e:\n",
    "            logging.warning(f\"Attempt {model}, {p_alias}, {fmt}, {size}, {i}, {s_q}, excepts for {e}\")\n",
    "\n",
    "            if attempt < MAX_RETRIES:\n",
    "                await asyncio.sleep(RETRY_DELAY * attempt)\n",
    "            else:\n",
    "                logging.error(f\"Request failed after {MAX_RETRIES} attempts: {model}, {p_alias}, {fmt}, {size}, {i}, {s_q}\")\n",
    "                return {\"error\": str(e), \"PK\": (model, p_alias, fmt, size, i, s_q), \"attempts\": attempt}\n",
    "    return await create_completion(session, content, p_alias, graph_data, fmt, model, size, i, q, pair, debug, attempt+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2efab-3cf8-489e-a081-be2f71051e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_completion(content:list, model: str):\n",
    "    \"\"\"Return what would be sent to LLM.\"\"\"\n",
    "    model_alias = \"deepseek-chat\" if model == \"deepseek-v3\" else model\n",
    "    json={\n",
    "        \"model\": model_alias,\n",
    "        \"max_completion_tokens\":8000,\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": content\n",
    "    }],\n",
    "        }\n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc13cd8-a900-4652-86ca-2d45005dd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def redo_task_by_pks(p_ks:list, debug=False, virtual=True, console=True):\n",
    "\n",
    "    timeout_seconds = 300\n",
    "    session_timeout = aiohttp.ClientTimeout(total=None,sock_connect=timeout_seconds,sock_read=timeout_seconds)\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession(timeout=session_timeout)as session:\n",
    "        for p_k in p_ks:\n",
    "            p_alias = p_k[\"p_alias\"]\n",
    "            fmt = p_k[\"fmt\"]\n",
    "            size = p_k[\"size\"]\n",
    "            ids = dict()\n",
    "            ids[size] = [int(p_k[\"i\"])]\n",
    "            d_questions = [p_k[\"q_combination\"]]\n",
    "            term = \"general\" if p_alias == \"SBM\" else \"special\"\n",
    "            model = p_k[\"model\"]\n",
    "            if d_questions[0][1] == \"shortest_path\":\n",
    "                try:\n",
    "                    d_pair = p_k[\"node_pair\"]\n",
    "                except Exception as e:\n",
    "                    d_pair = None\n",
    "            else:\n",
    "                d_pair = None\n",
    "            \n",
    "    \n",
    "            test_pk = (fmt, model, size)\n",
    "            tasks.extend(await perform_test(session, test_pk, p_alias, ids, d_questions, d_pair, debug, virtual, console))\n",
    "        if not console:\n",
    "            print(f\"Request count {len(tasks)}.\")\n",
    "        if not virtual:\n",
    "            results = await asyncio.gather(*tasks)\n",
    "\n",
    "            failed_requests = [res for res in results if \"error\" in res]\n",
    "            logging.info(f\"Failed Requests: {failed_requests}\")\n",
    "\n",
    "            with open(\"retry4retry.txt\", \"w\") as f:\n",
    "                f.write(\"\")\n",
    "            for req in failed_requests:\n",
    "                model, p_alias, fmt, size, i, q = req[\"PK\"] \n",
    "                with open(\"retry4retry.txt\", \"a\") as f:\n",
    "                    f.write(f\"Faild,{q},{p_alias}_{fmt}_{size}_{i}_results.txt\\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aebe370-c5cb-473c-bd84-71253be051c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def redo_task_from_file(model, filename: str, virtual=True, console=False):\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    p_ks = []\n",
    "    for l in lines:\n",
    "        no_pair_specified = None\n",
    "        _, q, data_p_k = l.split(\",\")\n",
    "        major_q, minor_q = q.split(\"_\", 1)\n",
    "        if minor_q == \"None\":\n",
    "            minor_q = None\n",
    "        if minor_q == \"shortest_path\":\n",
    "            try:\n",
    "                p_alias, fmt_1st_half, _, size, i, node0, node1, __ = data_p_k.split(\"_\")\n",
    "            except Exception as e:\n",
    "                no_pair_specified = True\n",
    "                p_alias, fmt_1st_half, _, size, i, __ = data_p_k.split(\"_\")\n",
    "        else:\n",
    "            p_alias, fmt_1st_half, _, size, i, __ = data_p_k.split(\"_\")\n",
    "        fmt = f\"{fmt_1st_half}_list\"\n",
    "        d = {\n",
    "            \"model\": model,\n",
    "            \"p_alias\": p_alias,\n",
    "            \"fmt\": fmt,\n",
    "            \"size\": size,\n",
    "            \"i\": i,\n",
    "            \"q_combination\": (major_q, minor_q)\n",
    "        }\n",
    "        if minor_q == \"shortest_path\" and no_pair_specified == None:\n",
    "            d[\"node_pair\"] = (node0, node1)\n",
    "        p_ks.append(d)\n",
    "    await redo_task_by_pks(p_ks, virtual=virtual, console=console)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865229c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage\n",
    "patterns = [\"Cycle\"]\n",
    "await do_task(patterns, d_size=\"exlarge\", d_model=\"deepseek-v3\", debug=False, virtual=True, console=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
